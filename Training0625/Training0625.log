2022-06-30 08:09:21.777100: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-30 08:09:22.891062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10884 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:65:00.0, compute capability: 6.0
2022-06-30 08:10:35.632091: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead
2022-06-30 08:10:41.271969: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
jetUps= (None, 30, 30, 2)
NNinputs= (None, 30, 30, 4)
ComplInput= (None, 30, 30, 6)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 2)            0           input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1, 1, 2)      0           concatenate[0][0]                
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 30, 30, 4)]  0                                            
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 30, 30, 2)    0           reshape[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 30, 6)    0           input_3[0][0]                    
                                                                 up_sampling2d[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 30, 30, 50)   14750       concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 30, 30, 20)   25020       conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 30, 20)   10020       conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 30, 30, 18)   9018        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 30, 30, 12)   1956        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 30, 30, 9)    981         conv2d_9[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 30, 30, 7)    574         conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 30, 30, 6)    384         conv2d_11[0][0]                  
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 30, 30, 3, 6) 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 30, 30, 3, 2) 0           conv2d_12[0][0]                  
==================================================================================================
Total params: 77,373
Trainable params: 77,373
Non-trainable params: 0
__________________________________________________________________________________________________
number of  file= 273
number of file validation= 68
total number of events = 8341541
total number of events validation= 2079273
Number of Steps= 130336.578125
training: start
Epoch 201/250
6516/6516 - 546s - loss: 0.7290 - reshape_1_loss: 0.3103 - reshape_2_loss: 0.4187 - val_loss: 0.7267 - val_reshape_1_loss: 0.3110 - val_reshape_2_loss: 0.4158

Epoch 00201: saving model to weights.201-0.73.hdf5
Epoch 202/250
6516/6516 - 528s - loss: 0.7277 - reshape_1_loss: 0.3092 - reshape_2_loss: 0.4185 - val_loss: 0.7291 - val_reshape_1_loss: 0.3111 - val_reshape_2_loss: 0.4180

Epoch 00202: saving model to weights.202-0.73.hdf5
Epoch 203/250
6516/6516 - 575s - loss: 0.7278 - reshape_1_loss: 0.3098 - reshape_2_loss: 0.4180 - val_loss: 0.7259 - val_reshape_1_loss: 0.3077 - val_reshape_2_loss: 0.4182

Epoch 00203: saving model to weights.203-0.73.hdf5
Epoch 204/250
6516/6516 - 619s - loss: 0.7288 - reshape_1_loss: 0.3101 - reshape_2_loss: 0.4187 - val_loss: 0.7237 - val_reshape_1_loss: 0.3068 - val_reshape_2_loss: 0.4169

Epoch 00204: saving model to weights.204-0.72.hdf5
Epoch 205/250
6516/6516 - 592s - loss: 0.7298 - reshape_1_loss: 0.3107 - reshape_2_loss: 0.4191 - val_loss: 0.7269 - val_reshape_1_loss: 0.3101 - val_reshape_2_loss: 0.4168

Epoch 00205: saving model to weights.205-0.73.hdf5
Epoch 206/250
6516/6516 - 569s - loss: 0.7330 - reshape_1_loss: 0.3125 - reshape_2_loss: 0.4205 - val_loss: 0.7317 - val_reshape_1_loss: 0.3130 - val_reshape_2_loss: 0.4186

Epoch 00206: saving model to weights.206-0.73.hdf5
Epoch 207/250
6516/6516 - 579s - loss: 0.7308 - reshape_1_loss: 0.3115 - reshape_2_loss: 0.4193 - val_loss: 0.7299 - val_reshape_1_loss: 0.3123 - val_reshape_2_loss: 0.4176

Epoch 00207: saving model to weights.207-0.73.hdf5
Epoch 208/250
6516/6516 - 592s - loss: 0.7308 - reshape_1_loss: 0.3123 - reshape_2_loss: 0.4185 - val_loss: 0.7250 - val_reshape_1_loss: 0.3085 - val_reshape_2_loss: 0.4165

Epoch 00208: saving model to weights.208-0.73.hdf5
Epoch 209/250
6516/6516 - 647s - loss: 0.7273 - reshape_1_loss: 0.3100 - reshape_2_loss: 0.4173 - val_loss: 0.7328 - val_reshape_1_loss: 0.3134 - val_reshape_2_loss: 0.4195

Epoch 00209: saving model to weights.209-0.73.hdf5
Epoch 210/250
6516/6516 - 631s - loss: 0.7294 - reshape_1_loss: 0.3107 - reshape_2_loss: 0.4187 - val_loss: 0.7300 - val_reshape_1_loss: 0.3115 - val_reshape_2_loss: 0.4185

Epoch 00210: saving model to weights.210-0.73.hdf5
Epoch 211/250
6516/6516 - 565s - loss: 0.7278 - reshape_1_loss: 0.3097 - reshape_2_loss: 0.4180 - val_loss: 0.7341 - val_reshape_1_loss: 0.3141 - val_reshape_2_loss: 0.4200

Epoch 00211: saving model to weights.211-0.73.hdf5
Epoch 212/250
6516/6516 - 558s - loss: 0.7310 - reshape_1_loss: 0.3113 - reshape_2_loss: 0.4197 - val_loss: 0.7288 - val_reshape_1_loss: 0.3106 - val_reshape_2_loss: 0.4182

Epoch 00212: saving model to weights.212-0.73.hdf5
Epoch 213/250
6516/6516 - 563s - loss: 0.7287 - reshape_1_loss: 0.3107 - reshape_2_loss: 0.4180 - val_loss: 0.7328 - val_reshape_1_loss: 0.3137 - val_reshape_2_loss: 0.4191

Epoch 00213: saving model to weights.213-0.73.hdf5
Epoch 214/250
6516/6516 - 610s - loss: 0.7258 - reshape_1_loss: 0.3083 - reshape_2_loss: 0.4175 - val_loss: 0.7222 - val_reshape_1_loss: 0.3049 - val_reshape_2_loss: 0.4173

Epoch 00214: saving model to weights.214-0.72.hdf5
Epoch 215/250
6516/6516 - 575s - loss: 0.7303 - reshape_1_loss: 0.3112 - reshape_2_loss: 0.4191 - val_loss: 0.7367 - val_reshape_1_loss: 0.3149 - val_reshape_2_loss: 0.4217

Epoch 00215: saving model to weights.215-0.74.hdf5
Epoch 216/250
6516/6516 - 570s - loss: 0.7298 - reshape_1_loss: 0.3111 - reshape_2_loss: 0.4187 - val_loss: 0.7305 - val_reshape_1_loss: 0.3119 - val_reshape_2_loss: 0.4186

Epoch 00216: saving model to weights.216-0.73.hdf5
Epoch 217/250
6516/6516 - 715s - loss: 0.7287 - reshape_1_loss: 0.3107 - reshape_2_loss: 0.4180 - val_loss: 0.7284 - val_reshape_1_loss: 0.3100 - val_reshape_2_loss: 0.4184

Epoch 00217: saving model to weights.217-0.73.hdf5
Epoch 218/250
6516/6516 - 936s - loss: 0.7303 - reshape_1_loss: 0.3114 - reshape_2_loss: 0.4189 - val_loss: 0.7272 - val_reshape_1_loss: 0.3087 - val_reshape_2_loss: 0.4185

Epoch 00218: saving model to weights.218-0.73.hdf5
Epoch 219/250
6516/6516 - 562s - loss: 0.7274 - reshape_1_loss: 0.3095 - reshape_2_loss: 0.4179 - val_loss: 0.7277 - val_reshape_1_loss: 0.3092 - val_reshape_2_loss: 0.4186

Epoch 00219: saving model to weights.219-0.73.hdf5
Epoch 220/250
6516/6516 - 555s - loss: 0.7266 - reshape_1_loss: 0.3087 - reshape_2_loss: 0.4179 - val_loss: 0.7330 - val_reshape_1_loss: 0.3127 - val_reshape_2_loss: 0.4203

Epoch 00220: saving model to weights.220-0.73.hdf5
Epoch 221/250
6516/6516 - 563s - loss: 0.7285 - reshape_1_loss: 0.3104 - reshape_2_loss: 0.4180 - val_loss: 0.7291 - val_reshape_1_loss: 0.3123 - val_reshape_2_loss: 0.4168

Epoch 00221: saving model to weights.221-0.73.hdf5
Epoch 222/250
6516/6516 - 553s - loss: 0.7264 - reshape_1_loss: 0.3085 - reshape_2_loss: 0.4179 - val_loss: 0.7305 - val_reshape_1_loss: 0.3116 - val_reshape_2_loss: 0.4190

Epoch 00222: saving model to weights.222-0.73.hdf5
Epoch 223/250
6516/6516 - 552s - loss: 0.7265 - reshape_1_loss: 0.3090 - reshape_2_loss: 0.4175 - val_loss: 0.7245 - val_reshape_1_loss: 0.3075 - val_reshape_2_loss: 0.4171

Epoch 00223: saving model to weights.223-0.72.hdf5
Epoch 224/250
6516/6516 - 550s - loss: 0.7282 - reshape_1_loss: 0.3098 - reshape_2_loss: 0.4184 - val_loss: 0.7224 - val_reshape_1_loss: 0.3070 - val_reshape_2_loss: 0.4154

Epoch 00224: saving model to weights.224-0.72.hdf5
Epoch 225/250
6516/6516 - 573s - loss: 0.7287 - reshape_1_loss: 0.3102 - reshape_2_loss: 0.4185 - val_loss: 0.7233 - val_reshape_1_loss: 0.3075 - val_reshape_2_loss: 0.4159

Epoch 00225: saving model to weights.225-0.72.hdf5
Epoch 226/250
6516/6516 - 560s - loss: 0.7301 - reshape_1_loss: 0.3110 - reshape_2_loss: 0.4192 - val_loss: 0.7315 - val_reshape_1_loss: 0.3135 - val_reshape_2_loss: 0.4180

Epoch 00226: saving model to weights.226-0.73.hdf5
Epoch 227/250
6516/6516 - 558s - loss: 0.7321 - reshape_1_loss: 0.3127 - reshape_2_loss: 0.4194 - val_loss: 0.7266 - val_reshape_1_loss: 0.3101 - val_reshape_2_loss: 0.4165

Epoch 00227: saving model to weights.227-0.73.hdf5
Epoch 228/250
6516/6516 - 583s - loss: 0.7288 - reshape_1_loss: 0.3106 - reshape_2_loss: 0.4182 - val_loss: 0.7239 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4156

Epoch 00228: saving model to weights.228-0.72.hdf5
Epoch 229/250
6516/6516 - 550s - loss: 0.7278 - reshape_1_loss: 0.3103 - reshape_2_loss: 0.4175 - val_loss: 0.7280 - val_reshape_1_loss: 0.3116 - val_reshape_2_loss: 0.4165

Epoch 00229: saving model to weights.229-0.73.hdf5
Epoch 230/250
6516/6516 - 562s - loss: 0.7272 - reshape_1_loss: 0.3096 - reshape_2_loss: 0.4176 - val_loss: 0.7286 - val_reshape_1_loss: 0.3112 - val_reshape_2_loss: 0.4174

Epoch 00230: saving model to weights.230-0.73.hdf5
Epoch 231/250
6516/6516 - 549s - loss: 0.7277 - reshape_1_loss: 0.3101 - reshape_2_loss: 0.4176 - val_loss: 0.7355 - val_reshape_1_loss: 0.3144 - val_reshape_2_loss: 0.4211

Epoch 00231: saving model to weights.231-0.74.hdf5
Epoch 232/250
6516/6516 - 554s - loss: 0.7285 - reshape_1_loss: 0.3097 - reshape_2_loss: 0.4188 - val_loss: 0.7281 - val_reshape_1_loss: 0.3108 - val_reshape_2_loss: 0.4173

Epoch 00232: saving model to weights.232-0.73.hdf5
Epoch 233/250
6516/6516 - 580s - loss: 0.7283 - reshape_1_loss: 0.3105 - reshape_2_loss: 0.4178 - val_loss: 0.7284 - val_reshape_1_loss: 0.3108 - val_reshape_2_loss: 0.4176

Epoch 00233: saving model to weights.233-0.73.hdf5
Epoch 234/250
6516/6516 - 600s - loss: 0.7250 - reshape_1_loss: 0.3082 - reshape_2_loss: 0.4167 - val_loss: 0.7233 - val_reshape_1_loss: 0.3064 - val_reshape_2_loss: 0.4169

Epoch 00234: saving model to weights.234-0.72.hdf5
Epoch 235/250
6516/6516 - 602s - loss: 0.7293 - reshape_1_loss: 0.3108 - reshape_2_loss: 0.4185 - val_loss: 0.7342 - val_reshape_1_loss: 0.3126 - val_reshape_2_loss: 0.4216

Epoch 00235: saving model to weights.235-0.73.hdf5
Epoch 236/250
6516/6516 - 604s - loss: 0.7283 - reshape_1_loss: 0.3102 - reshape_2_loss: 0.4181 - val_loss: 0.7300 - val_reshape_1_loss: 0.3124 - val_reshape_2_loss: 0.4176

Epoch 00236: saving model to weights.236-0.73.hdf5
Epoch 237/250
6516/6516 - 611s - loss: 0.7283 - reshape_1_loss: 0.3110 - reshape_2_loss: 0.4173 - val_loss: 0.7297 - val_reshape_1_loss: 0.3108 - val_reshape_2_loss: 0.4190

Epoch 00237: saving model to weights.237-0.73.hdf5
Epoch 238/250
6516/6516 - 600s - loss: 0.7285 - reshape_1_loss: 0.3102 - reshape_2_loss: 0.4183 - val_loss: 0.7281 - val_reshape_1_loss: 0.3097 - val_reshape_2_loss: 0.4184

Epoch 00238: saving model to weights.238-0.73.hdf5
Epoch 239/250
6516/6516 - 605s - loss: 0.7275 - reshape_1_loss: 0.3099 - reshape_2_loss: 0.4176 - val_loss: 0.7293 - val_reshape_1_loss: 0.3098 - val_reshape_2_loss: 0.4196

Epoch 00239: saving model to weights.239-0.73.hdf5
Epoch 240/250
6516/6516 - 608s - loss: 0.7262 - reshape_1_loss: 0.3090 - reshape_2_loss: 0.4172 - val_loss: 0.7307 - val_reshape_1_loss: 0.3116 - val_reshape_2_loss: 0.4191

Epoch 00240: saving model to weights.240-0.73.hdf5
Epoch 241/250
6516/6516 - 601s - loss: 0.7264 - reshape_1_loss: 0.3091 - reshape_2_loss: 0.4173 - val_loss: 0.7302 - val_reshape_1_loss: 0.3129 - val_reshape_2_loss: 0.4174

Epoch 00241: saving model to weights.241-0.73.hdf5
Epoch 242/250
6516/6516 - 611s - loss: 0.7271 - reshape_1_loss: 0.3092 - reshape_2_loss: 0.4179 - val_loss: 0.7273 - val_reshape_1_loss: 0.3091 - val_reshape_2_loss: 0.4182

Epoch 00242: saving model to weights.242-0.73.hdf5
Epoch 243/250
6516/6516 - 605s - loss: 0.7241 - reshape_1_loss: 0.3070 - reshape_2_loss: 0.4171 - val_loss: 0.7280 - val_reshape_1_loss: 0.3093 - val_reshape_2_loss: 0.4186

Epoch 00243: saving model to weights.243-0.73.hdf5
Epoch 244/250
6516/6516 - 613s - loss: 0.7278 - reshape_1_loss: 0.3101 - reshape_2_loss: 0.4178 - val_loss: 0.7222 - val_reshape_1_loss: 0.3058 - val_reshape_2_loss: 0.4164

Epoch 00244: saving model to weights.244-0.72.hdf5
Epoch 245/250
6516/6516 - 622s - loss: 0.7273 - reshape_1_loss: 0.3095 - reshape_2_loss: 0.4178 - val_loss: 0.7322 - val_reshape_1_loss: 0.3128 - val_reshape_2_loss: 0.4194

Epoch 00245: saving model to weights.245-0.73.hdf5
Epoch 246/250
6516/6516 - 615s - loss: 0.7294 - reshape_1_loss: 0.3109 - reshape_2_loss: 0.4184 - val_loss: 0.7293 - val_reshape_1_loss: 0.3122 - val_reshape_2_loss: 0.4172

Epoch 00246: saving model to weights.246-0.73.hdf5
Epoch 247/250
6516/6516 - 505s - loss: 0.7315 - reshape_1_loss: 0.3120 - reshape_2_loss: 0.4195 - val_loss: 0.7263 - val_reshape_1_loss: 0.3105 - val_reshape_2_loss: 0.4157

Epoch 00247: saving model to weights.247-0.73.hdf5
Epoch 248/250
6516/6516 - 514s - loss: 0.7267 - reshape_1_loss: 0.3096 - reshape_2_loss: 0.4171 - val_loss: 0.7235 - val_reshape_1_loss: 0.3082 - val_reshape_2_loss: 0.4153

Epoch 00248: saving model to weights.248-0.72.hdf5
Epoch 249/250
6516/6516 - 468s - loss: 0.7270 - reshape_1_loss: 0.3101 - reshape_2_loss: 0.4169 - val_loss: 0.7262 - val_reshape_1_loss: 0.3097 - val_reshape_2_loss: 0.4165

Epoch 00249: saving model to weights.249-0.73.hdf5
Epoch 250/250
6516/6516 - 510s - loss: 0.7274 - reshape_1_loss: 0.3097 - reshape_2_loss: 0.4177 - val_loss: 0.7279 - val_reshape_1_loss: 0.3111 - val_reshape_2_loss: 0.4168

Epoch 00250: saving model to weights.250-0.73.hdf5
done running; now save
training: completed
