2022-06-19 14:11:40.333185: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-19 14:11:41.348468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9961 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:65:00.0, compute capability: 6.0
2022-06-19 14:12:30.016057: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead
2022-06-19 14:12:31.841195: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
jetUps= (None, 30, 30, 2)
NNinputs= (None, 30, 30, 4)
ComplInput= (None, 30, 30, 6)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 2)            0           input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1, 1, 2)      0           concatenate[0][0]                
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 30, 30, 4)]  0                                            
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 30, 30, 2)    0           reshape[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 30, 6)    0           input_3[0][0]                    
                                                                 up_sampling2d[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 30, 30, 50)   14750       concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 30, 30, 20)   25020       conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 30, 20)   10020       conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 30, 30, 18)   9018        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 30, 30, 12)   1956        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 30, 30, 9)    981         conv2d_9[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 30, 30, 7)    574         conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 30, 30, 6)    384         conv2d_11[0][0]                  
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 30, 30, 3, 6) 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 30, 30, 3, 2) 0           conv2d_12[0][0]                  
==================================================================================================
Total params: 77,373
Trainable params: 77,373
Non-trainable params: 0
__________________________________________________________________________________________________
number of  file= 273
number of file validation= 68
total number of events = 8341541
total number of events validation= 2079273
Number of Steps= 130336.578125
training: start
Epoch 201/233
6516/6516 - 690s - loss: 0.7250 - reshape_1_loss: 0.3081 - reshape_2_loss: 0.4169 - val_loss: 0.7246 - val_reshape_1_loss: 0.3096 - val_reshape_2_loss: 0.4150

Epoch 00201: saving model to weights.201-0.72.hdf5
Epoch 202/233
6516/6516 - 706s - loss: 0.7233 - reshape_1_loss: 0.3068 - reshape_2_loss: 0.4165 - val_loss: 0.7269 - val_reshape_1_loss: 0.3100 - val_reshape_2_loss: 0.4170

Epoch 00202: saving model to weights.202-0.73.hdf5
Epoch 203/233
6516/6516 - 676s - loss: 0.7234 - reshape_1_loss: 0.3074 - reshape_2_loss: 0.4160 - val_loss: 0.7199 - val_reshape_1_loss: 0.3043 - val_reshape_2_loss: 0.4156

Epoch 00203: saving model to weights.203-0.72.hdf5
Epoch 204/233
6516/6516 - 700s - loss: 0.7241 - reshape_1_loss: 0.3077 - reshape_2_loss: 0.4165 - val_loss: 0.7194 - val_reshape_1_loss: 0.3046 - val_reshape_2_loss: 0.4148

Epoch 00204: saving model to weights.204-0.72.hdf5
Epoch 205/233
6516/6516 - 688s - loss: 0.7252 - reshape_1_loss: 0.3083 - reshape_2_loss: 0.4169 - val_loss: 0.7237 - val_reshape_1_loss: 0.3082 - val_reshape_2_loss: 0.4156

Epoch 00205: saving model to weights.205-0.72.hdf5
Epoch 206/233
6516/6516 - 703s - loss: 0.7282 - reshape_1_loss: 0.3100 - reshape_2_loss: 0.4182 - val_loss: 0.7272 - val_reshape_1_loss: 0.3108 - val_reshape_2_loss: 0.4163

Epoch 00206: saving model to weights.206-0.73.hdf5
Epoch 207/233
6516/6516 - 722s - loss: 0.7260 - reshape_1_loss: 0.3090 - reshape_2_loss: 0.4170 - val_loss: 0.7261 - val_reshape_1_loss: 0.3102 - val_reshape_2_loss: 0.4159

Epoch 00207: saving model to weights.207-0.73.hdf5
Epoch 208/233
6516/6516 - 710s - loss: 0.7260 - reshape_1_loss: 0.3098 - reshape_2_loss: 0.4162 - val_loss: 0.7214 - val_reshape_1_loss: 0.3068 - val_reshape_2_loss: 0.4146

Epoch 00208: saving model to weights.208-0.72.hdf5
Epoch 209/233
6516/6516 - 689s - loss: 0.7226 - reshape_1_loss: 0.3076 - reshape_2_loss: 0.4150 - val_loss: 0.7283 - val_reshape_1_loss: 0.3115 - val_reshape_2_loss: 0.4168

Epoch 00209: saving model to weights.209-0.73.hdf5
Epoch 210/233
6516/6516 - 642s - loss: 0.7241 - reshape_1_loss: 0.3080 - reshape_2_loss: 0.4161 - val_loss: 0.7257 - val_reshape_1_loss: 0.3093 - val_reshape_2_loss: 0.4164

Epoch 00210: saving model to weights.210-0.73.hdf5
Epoch 211/233
6516/6516 - 664s - loss: 0.7233 - reshape_1_loss: 0.3073 - reshape_2_loss: 0.4160 - val_loss: 0.7273 - val_reshape_1_loss: 0.3107 - val_reshape_2_loss: 0.4167

Epoch 00211: saving model to weights.211-0.73.hdf5
Epoch 212/233
6516/6516 - 709s - loss: 0.7267 - reshape_1_loss: 0.3090 - reshape_2_loss: 0.4177 - val_loss: 0.7251 - val_reshape_1_loss: 0.3085 - val_reshape_2_loss: 0.4166

Epoch 00212: saving model to weights.212-0.73.hdf5
Epoch 213/233
6516/6516 - 673s - loss: 0.7241 - reshape_1_loss: 0.3083 - reshape_2_loss: 0.4158 - val_loss: 0.7286 - val_reshape_1_loss: 0.3119 - val_reshape_2_loss: 0.4168

Epoch 00213: saving model to weights.213-0.73.hdf5
Epoch 214/233
6516/6516 - 698s - loss: 0.7213 - reshape_1_loss: 0.3060 - reshape_2_loss: 0.4153 - val_loss: 0.7186 - val_reshape_1_loss: 0.3027 - val_reshape_2_loss: 0.4159

Epoch 00214: saving model to weights.214-0.72.hdf5
Epoch 215/233
6516/6516 - 669s - loss: 0.7261 - reshape_1_loss: 0.3089 - reshape_2_loss: 0.4172 - val_loss: 0.7332 - val_reshape_1_loss: 0.3131 - val_reshape_2_loss: 0.4200

Epoch 00215: saving model to weights.215-0.73.hdf5
Epoch 216/233
6516/6516 - 700s - loss: 0.7254 - reshape_1_loss: 0.3087 - reshape_2_loss: 0.4167 - val_loss: 0.7249 - val_reshape_1_loss: 0.3093 - val_reshape_2_loss: 0.4156

Epoch 00216: saving model to weights.216-0.72.hdf5
Epoch 217/233
6516/6516 - 700s - loss: 0.7243 - reshape_1_loss: 0.3084 - reshape_2_loss: 0.4160 - val_loss: 0.7252 - val_reshape_1_loss: 0.3080 - val_reshape_2_loss: 0.4172

Epoch 00217: saving model to weights.217-0.73.hdf5
Epoch 218/233
6516/6516 - 705s - loss: 0.7259 - reshape_1_loss: 0.3090 - reshape_2_loss: 0.4169 - val_loss: 0.7233 - val_reshape_1_loss: 0.3062 - val_reshape_2_loss: 0.4171

Epoch 00218: saving model to weights.218-0.72.hdf5
Epoch 219/233
6516/6516 - 673s - loss: 0.7230 - reshape_1_loss: 0.3071 - reshape_2_loss: 0.4158 - val_loss: 0.7247 - val_reshape_1_loss: 0.3075 - val_reshape_2_loss: 0.4172

Epoch 00219: saving model to weights.219-0.72.hdf5
Epoch 220/233
6516/6516 - 667s - loss: 0.7225 - reshape_1_loss: 0.3065 - reshape_2_loss: 0.4160 - val_loss: 0.7260 - val_reshape_1_loss: 0.3092 - val_reshape_2_loss: 0.4168

Epoch 00220: saving model to weights.220-0.73.hdf5
Epoch 221/233
6516/6516 - 681s - loss: 0.7243 - reshape_1_loss: 0.3081 - reshape_2_loss: 0.4161 - val_loss: 0.7247 - val_reshape_1_loss: 0.3098 - val_reshape_2_loss: 0.4149

Epoch 00221: saving model to weights.221-0.72.hdf5
Epoch 222/233
6516/6516 - 691s - loss: 0.7223 - reshape_1_loss: 0.3062 - reshape_2_loss: 0.4161 - val_loss: 0.7249 - val_reshape_1_loss: 0.3079 - val_reshape_2_loss: 0.4170

Epoch 00222: saving model to weights.222-0.72.hdf5
Epoch 223/233
6516/6516 - 679s - loss: 0.7224 - reshape_1_loss: 0.3067 - reshape_2_loss: 0.4157 - val_loss: 0.7218 - val_reshape_1_loss: 0.3058 - val_reshape_2_loss: 0.4160

Epoch 00223: saving model to weights.223-0.72.hdf5
Epoch 224/233
6516/6516 - 704s - loss: 0.7239 - reshape_1_loss: 0.3075 - reshape_2_loss: 0.4164 - val_loss: 0.7203 - val_reshape_1_loss: 0.3059 - val_reshape_2_loss: 0.4144

Epoch 00224: saving model to weights.224-0.72.hdf5
Epoch 225/233
6516/6516 - 668s - loss: 0.7245 - reshape_1_loss: 0.3080 - reshape_2_loss: 0.4166 - val_loss: 0.7203 - val_reshape_1_loss: 0.3057 - val_reshape_2_loss: 0.4146

Epoch 00225: saving model to weights.225-0.72.hdf5
Epoch 226/233
6516/6516 - 677s - loss: 0.7259 - reshape_1_loss: 0.3087 - reshape_2_loss: 0.4172 - val_loss: 0.7284 - val_reshape_1_loss: 0.3119 - val_reshape_2_loss: 0.4165

Epoch 00226: saving model to weights.226-0.73.hdf5
Epoch 227/233
6516/6516 - 681s - loss: 0.7279 - reshape_1_loss: 0.3105 - reshape_2_loss: 0.4174 - val_loss: 0.7236 - val_reshape_1_loss: 0.3085 - val_reshape_2_loss: 0.4152

Epoch 00227: saving model to weights.227-0.72.hdf5
Epoch 228/233
6516/6516 - 694s - loss: 0.7247 - reshape_1_loss: 0.3085 - reshape_2_loss: 0.4163 - val_loss: 0.7215 - val_reshape_1_loss: 0.3068 - val_reshape_2_loss: 0.4147

Epoch 00228: saving model to weights.228-0.72.hdf5
Epoch 229/233
6516/6516 - 687s - loss: 0.7237 - reshape_1_loss: 0.3082 - reshape_2_loss: 0.4155 - val_loss: 0.7252 - val_reshape_1_loss: 0.3094 - val_reshape_2_loss: 0.4157

Epoch 00229: saving model to weights.229-0.73.hdf5
Epoch 230/233
6516/6516 - 686s - loss: 0.7228 - reshape_1_loss: 0.3074 - reshape_2_loss: 0.4155 - val_loss: 0.7252 - val_reshape_1_loss: 0.3097 - val_reshape_2_loss: 0.4155

Epoch 00230: saving model to weights.230-0.73.hdf5
Epoch 231/233
6516/6516 - 686s - loss: 0.7239 - reshape_1_loss: 0.3080 - reshape_2_loss: 0.4159 - val_loss: 0.7305 - val_reshape_1_loss: 0.3120 - val_reshape_2_loss: 0.4185

Epoch 00231: saving model to weights.231-0.73.hdf5
Epoch 232/233
6516/6516 - 690s - loss: 0.7248 - reshape_1_loss: 0.3076 - reshape_2_loss: 0.4172 - val_loss: 0.7248 - val_reshape_1_loss: 0.3091 - val_reshape_2_loss: 0.4157

Epoch 00232: saving model to weights.232-0.72.hdf5
Epoch 233/233
6516/6516 - 646s - loss: 0.7246 - reshape_1_loss: 0.3084 - reshape_2_loss: 0.4161 - val_loss: 0.7265 - val_reshape_1_loss: 0.3096 - val_reshape_2_loss: 0.4169

Epoch 00233: saving model to weights.233-0.73.hdf5
done running; now save
training: completed
