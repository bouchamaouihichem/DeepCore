2022-03-15 13:21:49.215965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 13:21:53.105680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2520 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:65:00.0, compute capability: 6.0
2022-03-15 13:23:00.563112: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead
2022-03-15 13:23:05.973414: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
jetUps= (None, 30, 30, 2)
NNinputs= (None, 30, 30, 7)
ComplInput= (None, 30, 30, 9)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 2)            0           input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1, 1, 2)      0           concatenate[0][0]                
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 30, 30, 7)]  0                                            
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 30, 30, 2)    0           reshape[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 30, 9)    0           input_3[0][0]                    
                                                                 up_sampling2d[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 30, 30, 50)   22100       concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 30, 30, 20)   25020       conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 30, 20)   10020       conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 30, 30, 18)   9018        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 30, 30, 12)   1956        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 30, 30, 9)    981         conv2d_9[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 30, 30, 7)    574         conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 30, 30, 6)    384         conv2d_11[0][0]                  
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 30, 30, 3, 6) 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 30, 30, 3, 2) 0           conv2d_12[0][0]                  
==================================================================================================
Total params: 84,723
Trainable params: 84,723
Non-trainable params: 0
__________________________________________________________________________________________________
number of  file= 273
number of file validation= 68
total number of events = 8341541
total number of events validation= 2079273
Number of Steps= 130336.578125
training: start
Epoch 253/302
130336/130336 - 11921s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4141

Epoch 00253: saving model to weights.253-0.72.hdf5
Epoch 254/302
130336/130336 - 11183s - loss: 0.7221 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00254: saving model to weights.254-0.72.hdf5
Epoch 255/302
130336/130336 - 9396s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00255: saving model to weights.255-0.72.hdf5
Epoch 256/302
130336/130336 - 9521s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00256: saving model to weights.256-0.72.hdf5
Epoch 257/302
130336/130336 - 11918s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00257: saving model to weights.257-0.72.hdf5
Epoch 258/302
130336/130336 - 12481s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00258: saving model to weights.258-0.72.hdf5
Epoch 259/302
130336/130336 - 10194s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00259: saving model to weights.259-0.72.hdf5
Epoch 260/302
130336/130336 - 13906s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00260: saving model to weights.260-0.72.hdf5
Epoch 261/302
130336/130336 - 14295s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00261: saving model to weights.261-0.72.hdf5
Epoch 262/302
130336/130336 - 12177s - loss: 0.7220 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00262: saving model to weights.262-0.72.hdf5
Epoch 263/302
130336/130336 - 12691s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7224 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4141

Epoch 00263: saving model to weights.263-0.72.hdf5
Epoch 264/302
130336/130336 - 10779s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7227 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4143

Epoch 00264: saving model to weights.264-0.72.hdf5
Epoch 265/302
130336/130336 - 9780s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00265: saving model to weights.265-0.72.hdf5
Epoch 266/302
130336/130336 - 9825s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00266: saving model to weights.266-0.72.hdf5
Epoch 267/302
130336/130336 - 15657s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00267: saving model to weights.267-0.72.hdf5
Epoch 268/302
130336/130336 - 9823s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00268: saving model to weights.268-0.72.hdf5
Epoch 269/302
130336/130336 - 9586s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00269: saving model to weights.269-0.72.hdf5
Epoch 270/302
130336/130336 - 9386s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00270: saving model to weights.270-0.72.hdf5
Epoch 271/302
130336/130336 - 16931s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00271: saving model to weights.271-0.72.hdf5
Epoch 272/302
130336/130336 - 20571s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00272: saving model to weights.272-0.72.hdf5
Epoch 273/302
130336/130336 - 20088s - loss: 0.7220 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00273: saving model to weights.273-0.72.hdf5
Epoch 274/302
130336/130336 - 24806s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00274: saving model to weights.274-0.72.hdf5
Epoch 275/302
130336/130336 - 21233s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00275: saving model to weights.275-0.72.hdf5
Epoch 276/302
130336/130336 - 20079s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00276: saving model to weights.276-0.72.hdf5
Epoch 277/302
130336/130336 - 19974s - loss: 0.7220 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00277: saving model to weights.277-0.72.hdf5
Epoch 278/302
130336/130336 - 21272s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00278: saving model to weights.278-0.72.hdf5
Epoch 279/302
130336/130336 - 14110s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00279: saving model to weights.279-0.72.hdf5
Epoch 280/302
130336/130336 - 9746s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00280: saving model to weights.280-0.72.hdf5
Epoch 281/302
130336/130336 - 9797s - loss: 0.7219 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00281: saving model to weights.281-0.72.hdf5
Epoch 282/302
130336/130336 - 10761s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00282: saving model to weights.282-0.72.hdf5
Epoch 283/302
130336/130336 - 12658s - loss: 0.7219 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00283: saving model to weights.283-0.72.hdf5
Epoch 284/302
130336/130336 - 12689s - loss: 0.7221 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7224 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4141

Epoch 00284: saving model to weights.284-0.72.hdf5
Epoch 285/302
130336/130336 - 12673s - loss: 0.7220 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00285: saving model to weights.285-0.72.hdf5
Epoch 286/302
130336/130336 - 12668s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7224 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4141

Epoch 00286: saving model to weights.286-0.72.hdf5
Epoch 287/302
130336/130336 - 12699s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7224 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4141

Epoch 00287: saving model to weights.287-0.72.hdf5
Epoch 288/302
130336/130336 - 12612s - loss: 0.7219 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00288: saving model to weights.288-0.72.hdf5
Epoch 289/302
130336/130336 - 12166s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00289: saving model to weights.289-0.72.hdf5
Epoch 290/302
130336/130336 - 12537s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00290: saving model to weights.290-0.72.hdf5
Epoch 291/302
130336/130336 - 16218s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00291: saving model to weights.291-0.72.hdf5
Epoch 292/302
130336/130336 - 19405s - loss: 0.7221 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7227 - val_reshape_1_loss: 0.3085 - val_reshape_2_loss: 0.4142

Epoch 00292: saving model to weights.292-0.72.hdf5
Epoch 293/302
130336/130336 - 18413s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00293: saving model to weights.293-0.72.hdf5
Epoch 294/302
130336/130336 - 17607s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7227 - val_reshape_1_loss: 0.3085 - val_reshape_2_loss: 0.4142

Epoch 00294: saving model to weights.294-0.72.hdf5
Epoch 295/302
130336/130336 - 13114s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00295: saving model to weights.295-0.72.hdf5
Epoch 296/302
130336/130336 - 18207s - loss: 0.7220 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4142 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00296: saving model to weights.296-0.72.hdf5
Epoch 297/302
130336/130336 - 18656s - loss: 0.7220 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4142 - val_loss: 0.7225 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00297: saving model to weights.297-0.72.hdf5
Epoch 298/302
130336/130336 - 21597s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7225 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4142

Epoch 00298: saving model to weights.298-0.72.hdf5
Epoch 299/302
130336/130336 - 16267s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00299: saving model to weights.299-0.72.hdf5
Epoch 300/302
130336/130336 - 16336s - loss: 0.7219 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4141 - val_loss: 0.7224 - val_reshape_1_loss: 0.3082 - val_reshape_2_loss: 0.4142

Epoch 00300: saving model to weights.300-0.72.hdf5
Epoch 301/302
130336/130336 - 18471s - loss: 0.7220 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4141 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00301: saving model to weights.301-0.72.hdf5
Epoch 302/302
130336/130336 - 18922s - loss: 0.7220 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4142 - val_loss: 0.7226 - val_reshape_1_loss: 0.3084 - val_reshape_2_loss: 0.4142

Epoch 00302: saving model to weights.302-0.72.hdf5
done running; now save
training: completed
