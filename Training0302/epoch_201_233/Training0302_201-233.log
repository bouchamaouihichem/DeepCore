2022-03-07 07:30:28.134512: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-07 07:30:28.949232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11323 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:65:00.0, compute capability: 6.0
2022-03-07 07:31:15.561221: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead
2022-03-07 07:31:17.294380: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
jetUps= (None, 30, 30, 2)
NNinputs= (None, 30, 30, 7)
ComplInput= (None, 30, 30, 9)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 2)            0           input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1, 1, 2)      0           concatenate[0][0]                
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 30, 30, 7)]  0                                            
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 30, 30, 2)    0           reshape[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 30, 9)    0           input_3[0][0]                    
                                                                 up_sampling2d[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 30, 30, 50)   22100       concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 30, 30, 20)   25020       conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 30, 20)   10020       conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 30, 30, 18)   9018        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 30, 30, 12)   1956        conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 30, 30, 9)    981         conv2d_9[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 30, 30, 7)    574         conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 30, 30, 18)   2934        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 30, 30, 6)    384         conv2d_11[0][0]                  
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 30, 30, 3, 6) 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 30, 30, 3, 2) 0           conv2d_12[0][0]                  
==================================================================================================
Total params: 84,723
Trainable params: 84,723
Non-trainable params: 0
__________________________________________________________________________________________________
number of  file= 273
number of file validation= 68
total number of events = 8341541
total number of events validation= 2079273
Number of Steps= 130336.578125
training: start
Epoch 201/233
6516/6516 - 728s - loss: 0.7237 - reshape_1_loss: 0.3085 - reshape_2_loss: 0.4152 - val_loss: 0.7231 - val_reshape_1_loss: 0.3100 - val_reshape_2_loss: 0.4131

Epoch 00201: saving model to weights.201-0.72.hdf5
Epoch 202/233
6516/6516 - 703s - loss: 0.7219 - reshape_1_loss: 0.3072 - reshape_2_loss: 0.4147 - val_loss: 0.7256 - val_reshape_1_loss: 0.3103 - val_reshape_2_loss: 0.4153

Epoch 00202: saving model to weights.202-0.73.hdf5
Epoch 203/233
6516/6516 - 667s - loss: 0.7221 - reshape_1_loss: 0.3078 - reshape_2_loss: 0.4143 - val_loss: 0.7187 - val_reshape_1_loss: 0.3046 - val_reshape_2_loss: 0.4141

Epoch 00203: saving model to weights.203-0.72.hdf5
Epoch 204/233
6516/6516 - 698s - loss: 0.7228 - reshape_1_loss: 0.3080 - reshape_2_loss: 0.4148 - val_loss: 0.7182 - val_reshape_1_loss: 0.3049 - val_reshape_2_loss: 0.4134

Epoch 00204: saving model to weights.204-0.72.hdf5
Epoch 205/233
6516/6516 - 675s - loss: 0.7239 - reshape_1_loss: 0.3087 - reshape_2_loss: 0.4152 - val_loss: 0.7222 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4139

Epoch 00205: saving model to weights.205-0.72.hdf5
Epoch 206/233
6516/6516 - 684s - loss: 0.7269 - reshape_1_loss: 0.3104 - reshape_2_loss: 0.4165 - val_loss: 0.7257 - val_reshape_1_loss: 0.3112 - val_reshape_2_loss: 0.4145

Epoch 00206: saving model to weights.206-0.73.hdf5
Epoch 207/233
6516/6516 - 698s - loss: 0.7248 - reshape_1_loss: 0.3094 - reshape_2_loss: 0.4154 - val_loss: 0.7247 - val_reshape_1_loss: 0.3105 - val_reshape_2_loss: 0.4141

Epoch 00207: saving model to weights.207-0.72.hdf5
Epoch 208/233
6516/6516 - 687s - loss: 0.7245 - reshape_1_loss: 0.3102 - reshape_2_loss: 0.4143 - val_loss: 0.7204 - val_reshape_1_loss: 0.3071 - val_reshape_2_loss: 0.4132

Epoch 00208: saving model to weights.208-0.72.hdf5
Epoch 209/233
6516/6516 - 718s - loss: 0.7213 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4134 - val_loss: 0.7267 - val_reshape_1_loss: 0.3118 - val_reshape_2_loss: 0.4149

Epoch 00209: saving model to weights.209-0.73.hdf5
Epoch 210/233
6516/6516 - 632s - loss: 0.7227 - reshape_1_loss: 0.3084 - reshape_2_loss: 0.4143 - val_loss: 0.7244 - val_reshape_1_loss: 0.3096 - val_reshape_2_loss: 0.4149

Epoch 00210: saving model to weights.210-0.72.hdf5
Epoch 211/233
6516/6516 - 614s - loss: 0.7220 - reshape_1_loss: 0.3077 - reshape_2_loss: 0.4143 - val_loss: 0.7258 - val_reshape_1_loss: 0.3109 - val_reshape_2_loss: 0.4150

Epoch 00211: saving model to weights.211-0.73.hdf5
Epoch 212/233
6516/6516 - 593s - loss: 0.7254 - reshape_1_loss: 0.3094 - reshape_2_loss: 0.4160 - val_loss: 0.7234 - val_reshape_1_loss: 0.3088 - val_reshape_2_loss: 0.4146

Epoch 00212: saving model to weights.212-0.72.hdf5
Epoch 213/233
6516/6516 - 585s - loss: 0.7228 - reshape_1_loss: 0.3087 - reshape_2_loss: 0.4141 - val_loss: 0.7271 - val_reshape_1_loss: 0.3120 - val_reshape_2_loss: 0.4151

Epoch 00213: saving model to weights.213-0.73.hdf5
Epoch 214/233
6516/6516 - 589s - loss: 0.7201 - reshape_1_loss: 0.3063 - reshape_2_loss: 0.4138 - val_loss: 0.7173 - val_reshape_1_loss: 0.3032 - val_reshape_2_loss: 0.4141

Epoch 00214: saving model to weights.214-0.72.hdf5
Epoch 215/233
6516/6516 - 601s - loss: 0.7249 - reshape_1_loss: 0.3094 - reshape_2_loss: 0.4155 - val_loss: 0.7321 - val_reshape_1_loss: 0.3136 - val_reshape_2_loss: 0.4185

Epoch 00215: saving model to weights.215-0.73.hdf5
Epoch 216/233
6516/6516 - 582s - loss: 0.7241 - reshape_1_loss: 0.3090 - reshape_2_loss: 0.4151 - val_loss: 0.7243 - val_reshape_1_loss: 0.3097 - val_reshape_2_loss: 0.4145

Epoch 00216: saving model to weights.216-0.72.hdf5
Epoch 217/233
6516/6516 - 584s - loss: 0.7228 - reshape_1_loss: 0.3088 - reshape_2_loss: 0.4140 - val_loss: 0.7232 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4149

Epoch 00217: saving model to weights.217-0.72.hdf5
Epoch 218/233
6516/6516 - 605s - loss: 0.7246 - reshape_1_loss: 0.3094 - reshape_2_loss: 0.4152 - val_loss: 0.7220 - val_reshape_1_loss: 0.3068 - val_reshape_2_loss: 0.4153

Epoch 00218: saving model to weights.218-0.72.hdf5
Epoch 219/233
6516/6516 - 587s - loss: 0.7218 - reshape_1_loss: 0.3076 - reshape_2_loss: 0.4142 - val_loss: 0.7238 - val_reshape_1_loss: 0.3079 - val_reshape_2_loss: 0.4159

Epoch 00219: saving model to weights.219-0.72.hdf5
Epoch 220/233
6516/6516 - 595s - loss: 0.7212 - reshape_1_loss: 0.3069 - reshape_2_loss: 0.4143 - val_loss: 0.7243 - val_reshape_1_loss: 0.3095 - val_reshape_2_loss: 0.4147

Epoch 00220: saving model to weights.220-0.72.hdf5
Epoch 221/233
6516/6516 - 596s - loss: 0.7231 - reshape_1_loss: 0.3086 - reshape_2_loss: 0.4145 - val_loss: 0.7235 - val_reshape_1_loss: 0.3103 - val_reshape_2_loss: 0.4132

Epoch 00221: saving model to weights.221-0.72.hdf5
Epoch 222/233
6516/6516 - 593s - loss: 0.7210 - reshape_1_loss: 0.3067 - reshape_2_loss: 0.4143 - val_loss: 0.7236 - val_reshape_1_loss: 0.3083 - val_reshape_2_loss: 0.4154

Epoch 00222: saving model to weights.222-0.72.hdf5
Epoch 223/233
6516/6516 - 588s - loss: 0.7210 - reshape_1_loss: 0.3071 - reshape_2_loss: 0.4139 - val_loss: 0.7208 - val_reshape_1_loss: 0.3062 - val_reshape_2_loss: 0.4146

Epoch 00223: saving model to weights.223-0.72.hdf5
Epoch 224/233
6516/6516 - 607s - loss: 0.7226 - reshape_1_loss: 0.3079 - reshape_2_loss: 0.4148 - val_loss: 0.7190 - val_reshape_1_loss: 0.3061 - val_reshape_2_loss: 0.4128

Epoch 00224: saving model to weights.224-0.72.hdf5
Epoch 225/233
6516/6516 - 691s - loss: 0.7232 - reshape_1_loss: 0.3083 - reshape_2_loss: 0.4149 - val_loss: 0.7192 - val_reshape_1_loss: 0.3060 - val_reshape_2_loss: 0.4132

Epoch 00225: saving model to weights.225-0.72.hdf5
Epoch 226/233
6516/6516 - 701s - loss: 0.7246 - reshape_1_loss: 0.3091 - reshape_2_loss: 0.4155 - val_loss: 0.7268 - val_reshape_1_loss: 0.3122 - val_reshape_2_loss: 0.4146

Epoch 00226: saving model to weights.226-0.73.hdf5
Epoch 227/233
6516/6516 - 584s - loss: 0.7266 - reshape_1_loss: 0.3109 - reshape_2_loss: 0.4157 - val_loss: 0.7222 - val_reshape_1_loss: 0.3089 - val_reshape_2_loss: 0.4134

Epoch 00227: saving model to weights.227-0.72.hdf5
Epoch 228/233
6516/6516 - 560s - loss: 0.7233 - reshape_1_loss: 0.3088 - reshape_2_loss: 0.4145 - val_loss: 0.7206 - val_reshape_1_loss: 0.3072 - val_reshape_2_loss: 0.4134

Epoch 00228: saving model to weights.228-0.72.hdf5
Epoch 229/233
6516/6516 - 492s - loss: 0.7225 - reshape_1_loss: 0.3086 - reshape_2_loss: 0.4139 - val_loss: 0.7237 - val_reshape_1_loss: 0.3098 - val_reshape_2_loss: 0.4139

Epoch 00229: saving model to weights.229-0.72.hdf5
Epoch 230/233
6516/6516 - 520s - loss: 0.7215 - reshape_1_loss: 0.3077 - reshape_2_loss: 0.4137 - val_loss: 0.7237 - val_reshape_1_loss: 0.3098 - val_reshape_2_loss: 0.4138

Epoch 00230: saving model to weights.230-0.72.hdf5
Epoch 231/233
6516/6516 - 588s - loss: 0.7225 - reshape_1_loss: 0.3084 - reshape_2_loss: 0.4141 - val_loss: 0.7289 - val_reshape_1_loss: 0.3122 - val_reshape_2_loss: 0.4168

Epoch 00231: saving model to weights.231-0.73.hdf5
Epoch 232/233
6516/6516 - 564s - loss: 0.7236 - reshape_1_loss: 0.3080 - reshape_2_loss: 0.4155 - val_loss: 0.7232 - val_reshape_1_loss: 0.3094 - val_reshape_2_loss: 0.4138

Epoch 00232: saving model to weights.232-0.72.hdf5
Epoch 233/233
6516/6516 - 635s - loss: 0.7232 - reshape_1_loss: 0.3089 - reshape_2_loss: 0.4143 - val_loss: 0.7250 - val_reshape_1_loss: 0.3098 - val_reshape_2_loss: 0.4152

Epoch 00233: saving model to weights.233-0.72.hdf5
done running; now save
training: completed
